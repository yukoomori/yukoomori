{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### Import Libraries ###\n",
    "########################\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import split_folders\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### 1. Data Preparation ###\n",
    "###########################\n",
    "\n",
    "# Current working directory\n",
    "projectFolder = os.getcwd()\n",
    "\n",
    "# Assign directories to variables\n",
    "images_dir        = projectFolder + '/images'\n",
    "base_dir          = images_dir + '/base'\n",
    "base_OK_dir       = base_dir + '/OK'\n",
    "base_NG_dir       = base_dir + '/NG'\n",
    "_OKlist           = os.listdir(base_OK_dir)  # type list\n",
    "_NGlist           = os.listdir(base_NG_dir)  # type list\n",
    "\n",
    "# Parameters\n",
    "model_name        = \"<model_name>.h5\"\n",
    "seed              = 1337\n",
    "ratios            = (.7, .15, .15)\n",
    "bs                = 32\n",
    "\n",
    "# Model fit parameters\n",
    "steps_per_epoch   = 40\n",
    "epochs            = 15\n",
    "validation_steps  = 15\n",
    "\n",
    "# Split base -> train, validate, test by ratios\n",
    "# Automatically creates folders train, val, test\n",
    "split_folders.ratio(base_dir,               # input folder\n",
    "                    output = images_dir,    # output folder\n",
    "                    seed = seed,            # seed for reproduction\n",
    "                    ratio = ratios)         # ratio of train, validate, test\n",
    "\n",
    "# Data File Path\n",
    "train_dir         = images_dir + '/train'\n",
    "validation_dir    = images_dir + '/val'\n",
    "test_dir          = images_dir + '/test'\n",
    "\n",
    "train_OK_dir      = train_dir + '/OK'\n",
    "train_NG_dir      = train_dir + '/NG'\n",
    "validation_OK_dir = validation_dir + '/OK'\n",
    "validation_NG_dir = validation_dir + '/NG'\n",
    "test_OK_dir       = test_dir + '/OK'\n",
    "test_NG_dir       = test_dir + '/NG'\n",
    "\n",
    "# Print total number of files per folder\n",
    "print('1.0\\tbase/OK  : ', len(_OKlist), '\\tbase/NG  : ', len(_NGlist))\n",
    "print('-------------------------------------------------')\n",
    "print(ratios[0], '\\ttrain/OK : ', len(os.listdir(train_OK_dir)), '\\ttrain/NG : ', len(os.listdir(train_NG_dir)))\n",
    "print(ratios[1], '\\tval/ OK  : ', len(os.listdir(validation_OK_dir)), '\\tval/ NG  : ', len(os.listdir(validation_NG_dir)))\n",
    "print(ratios[2], '\\ttest/ OK : ', len(os.listdir(test_OK_dir)), '\\ttest/ NG : ', len(os.listdir(test_NG_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### 2. Data Preprocessing ###\n",
    "#############################\n",
    "\n",
    "# Define the configuration for image data preparation and augmentation for train and test\n",
    "# Feature standardizaton is set by default\n",
    "# zca_whitening = False\n",
    "train_datagen = ImageDataGenerator(rescale=1./255) # Convention to name it XX_datagen\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Apply transformation settings onto train_dir\n",
    "# train_dir (1638 + 1638 = 3276 images)\n",
    "# ImageDataGenerator().flow_from_directory(directory)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size = (256,256),\n",
    "    batch_size = bs,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "# validation_dir (351 + 351 = 702 images)\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir, \n",
    "    target_size = (256,256),\n",
    "    batch_size = bs,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### 3. Create Model ###\n",
    "#######################\n",
    "# As you go deeper into the neural network, number of filters in Conv2D typically double in order to learn more and more sophisticated types of features.\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Conv2D(filters = 32, kernel_size = (3, 3), activation='relu', input_shape=(250, 250, 3))\n",
    "# reLu = Rectify Linear Unit\n",
    "# filter is the output dimension of the output filter\n",
    "# kernel size is sometimes referred to as kernel matrix\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "# MaxPooling2D - Make our image much smaller\n",
    "# filter_size = 2 so (2, 2) window,  stride = 2  so maxpool every 2 pixels\n",
    "#  Essentially, a maxpooling(2, 2) resizes picture  to 1/4 of its original size i.e. 256 x 256 -> 128 x 128\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# 128 x 128 -> 64 x 64\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# 64 x 64 -> 32 x 32\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# 32 x 32 = 16 x 16\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "\n",
    "# Flatten turns data from 2D vector to 1D array\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### 4. Compile Model ###\n",
    "########################\n",
    "\n",
    "# Loss function as binary crossentropy\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = optimizers.RMSprop(lr=1e-4),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### 5. Train Model ###\n",
    "######################\n",
    "\n",
    "# The Keras deep learning library includes three separate functions that can be used to train your own models:\n",
    "## .fit()\n",
    "## .fit_generator()\n",
    "## .train_on_batch()\n",
    "\n",
    "# Number of training samples in images/train folder\n",
    "train_num_files = len(os.listdir(train_OK_dir)) + len(os.listdir(train_NG_dir))\n",
    "train_num_files\n",
    "\n",
    "val_num_files = len(os.listdir(validation_OK_dir)) + len(os.listdir(validation_NG_dir))\n",
    "val_num_files\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch  = steps_per_epoch,\n",
    "                             epochs           = epochs,\n",
    "                             validation_data  = validation_generator,\n",
    "                             validation_steps = validation_steps)\n",
    "\n",
    "# Save Model\n",
    "try:\n",
    "    os.mkdir(projectFolder + '/Models')\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")\n",
    "model.save(projectFolder + \"/Models/\" + model_name)\n",
    "print(\"Saved model \" + model_name + \" in \" + projectFolder + '/Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "### 6. Visualize Improvements in Accuracy and Loss ###\n",
    "######################################################\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_ = range(1, len(acc) + 1)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.plot(epochs_, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs_, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot Loss\n",
    "plt.plot(epochs_, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs_, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### 7. Test Model ###\n",
    "#####################\n",
    "\n",
    "# Load Model\n",
    "model = models.load_model(projectFolder + '/Models/' + model_name)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # Convention to name it XX_datagen\n",
    "\n",
    "# Apply transformation settings onto test_dir\n",
    "# test_dir (540 + 540 = 1080 images)\n",
    "# ImageDataGenerator().flow_from_directory(directory)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(256,256), # target_size(height, width), dimentions to which all images wil be resized to\n",
    "    batch_size=bs,         # size of batch of data (default = 32)\n",
    "    class_mode = 'binary') # class_mode = binary because either OK or NG (output = 1D binary labels)\n",
    "\n",
    "loss, acc = model.evaluate(test_generator[0][0], test_generator[0][1])\n",
    "print('Test loss: %s, Test acc: %s' % (loss, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
